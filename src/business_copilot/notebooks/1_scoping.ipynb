{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8232107-7e90-49f4-b899-9a54e9cba8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from typing import Any\n",
    "import asyncpg\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25092ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv(find_dotenv())\n",
    "postgres_uri = os.environ.get(\"DATABASE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe976ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PostgreSQL:\n",
    "    def __init__(self,\n",
    "                 *,\n",
    "                 uri: Any | None=None,\n",
    "                 **kwargs,\n",
    "                 )-> None:\n",
    "        self._dialect = \"postgresql\"\n",
    "        self.uri = uri\n",
    "        self.config = kwargs\n",
    "        self.conn = None\n",
    "\n",
    "    @property\n",
    "    def dialect(self, ):\n",
    "        return self._dialect\n",
    "\n",
    "    async def connect(self, ) -> None:\n",
    "        self.conn = await asyncpg.connect(\n",
    "            dsn=self.uri,\n",
    "            **self.config,                                          \n",
    "        )\n",
    "\n",
    "    async def create_table_schema(self, table_name: str) -> str:\n",
    "        # Get columns\n",
    "        columns = await self.conn.fetch(f\"\"\"\n",
    "            SELECT column_name, data_type, is_nullable, character_maximum_length\n",
    "            FROM information_schema.columns\n",
    "            WHERE table_name = '{table_name}'\n",
    "            ORDER BY ordinal_position;\n",
    "        \"\"\")\n",
    "\n",
    "        # Get primary keys\n",
    "        pk_rows = await self.conn.fetch(f\"\"\"\n",
    "            SELECT a.attname\n",
    "            FROM pg_index i\n",
    "            JOIN pg_attribute a ON a.attrelid = i.indrelid AND a.attnum = ANY(i.indkey)\n",
    "            WHERE i.indrelid = '{table_name}'::regclass AND i.indisprimary;\n",
    "        \"\"\")\n",
    "        primary_keys = [row['attname'] for row in pk_rows]\n",
    "\n",
    "        # Get foreign keys\n",
    "        fk_rows = await self.conn.fetch(f\"\"\"\n",
    "            SELECT\n",
    "                kcu.column_name,\n",
    "                ccu.table_name AS foreign_table,\n",
    "                ccu.column_name AS foreign_column\n",
    "            FROM information_schema.table_constraints AS tc\n",
    "            JOIN information_schema.key_column_usage AS kcu\n",
    "                ON tc.constraint_name = kcu.constraint_name\n",
    "            JOIN information_schema.constraint_column_usage AS ccu\n",
    "                ON ccu.constraint_name = tc.constraint_name\n",
    "            WHERE tc.constraint_type = 'FOREIGN KEY' AND tc.table_name = '{table_name}';\n",
    "        \"\"\")\n",
    "\n",
    "        # Build column definitions\n",
    "        col_defs = []\n",
    "        for col in columns:\n",
    "            name = f'\"{col[\"column_name\"]}\"'\n",
    "            dtype = col[\"data_type\"].upper()\n",
    "            if dtype == \"CHARACTER VARYING\":\n",
    "                dtype = f'NVARCHAR({col[\"character_maximum_length\"]})'\n",
    "            elif dtype == \"CHARACTER\":\n",
    "                dtype = f'NCHAR({col[\"character_maximum_length\"]})'\n",
    "            elif dtype == \"TEXT\":\n",
    "                dtype = \"TEXT\"\n",
    "            elif dtype == \"INTEGER\":\n",
    "                dtype = \"INTEGER\"\n",
    "            # Add more type mappings if needed\n",
    "\n",
    "            nullable = \"NOT NULL\" if col[\"is_nullable\"] == \"NO\" else \"\"\n",
    "            col_defs.append(f\"{name} {dtype} {nullable}\".strip())\n",
    "\n",
    "        # Add primary key\n",
    "        if primary_keys:\n",
    "            pk = ', '.join(f'\"{key}\"' for key in primary_keys)\n",
    "            col_defs.append(f\"PRIMARY KEY ({pk})\")\n",
    "\n",
    "        # Add foreign keys\n",
    "        for fk in fk_rows:\n",
    "            col_defs.append(\n",
    "                f'FOREIGN KEY(\"{fk[\"column_name\"]}\") REFERENCES \"{fk[\"foreign_table\"]}\" (\"{fk[\"foreign_column\"]}\")'\n",
    "            )\n",
    "\n",
    "        # Final SQL\n",
    "        sql = f'CREATE TABLE \"{table_name}\" (\\n\\t' + ',\\n\\t'.join(col_defs) + '\\n);'     \n",
    "        return sql\n",
    "    \n",
    "    \n",
    "    async def list_tables(self, )-> list[str]:\n",
    "        rows = await self.conn.fetch(\"\"\"\n",
    "            SELECT tablename\n",
    "            FROM pg_catalog.pg_tables\n",
    "            WHERE schemaname != 'pg_catalog' AND schemaname != 'information_schema';\n",
    "        \"\"\")\n",
    "        return [row['tablename'].title() for row in rows]\n",
    "\n",
    "    async def get_example(self, table_name: str) -> str:\n",
    "         # Execute a query\n",
    "        values = await self.conn.fetch(\n",
    "            f\"SELECT * FROM {table_name} LIMIT 3;\",\n",
    "\n",
    "        )\n",
    "        examples = []\n",
    "        for item in values:\n",
    "            examples.append(list(item.items()))\n",
    "\n",
    "        records = [dict(row) for row in examples]\n",
    "        \n",
    "        table = pd.DataFrame(records).to_string()\n",
    "\n",
    "        return (\"/*\\n\" + f\"3 rows from '{table_name}' table:\\n\" + table + \"\\n\"+\n",
    "                \"*/\"\n",
    "        )\n",
    "\n",
    "    async def get_all_table_schema_example(self) -> str:\n",
    "        table_names = await self.list_tables()\n",
    "        all_schema = \"\"\n",
    "        for t_names in table_names:\n",
    "            tab = await self.create_table_schema(t_names.lower())\n",
    "            example = await self.get_example(t_names.lower())\n",
    "\n",
    "            all_schema += tab + \"\\n\\n\" + example + \"\\n\\n\"\n",
    "            \n",
    "        return all_schema\n",
    "\n",
    "    async def execute(self, query: str) -> asyncpg.Record:\n",
    "        # Execute a query\n",
    "        values = await self.conn.fetch(\n",
    "            query,\n",
    "\n",
    "        )\n",
    "        await self.clean_up()\n",
    "        return values\n",
    "    \n",
    "    async def clean_up(self) -> None:\n",
    "        await self.conn.close()\n",
    "        \n",
    "psql = PostgreSQL(uri=postgres_uri)\n",
    "await psql.connect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e002e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "await psql.list_tables()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39c60d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = await psql.get_example(\"customer\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a441500f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(psql.dialect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0332f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = await psql.create_table_schema(\"album\")\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbdc220",
   "metadata": {},
   "outputs": [],
   "source": [
    "schemas_examples = await psql.get_all_table_schema_example()\n",
    "print(schemas_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89149ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = \"gpt-4o\"\n",
    "model_provider = \"openai\"\n",
    "# Instantiate the chat model\n",
    "llm = init_chat_model(f\"{model_provider}:{model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b0d49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test that it works\n",
    "output = await llm.ainvoke(\"hi!\") # call the model\n",
    "output.content  # Get the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6357937e-d215-4ea1-9a28-61fcba60420f",
   "metadata": {},
   "outputs": [],
   "source": [
    "async for step in llm.astream(\"hello how are you\"):\n",
    "    print(step.content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f8a93f-336e-4022-9d81-ef21892e639e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from business_copilot.biz_analytics.db_tools import (list_tables, \n",
    "                                                     get_relevant_schema_example, \n",
    "                                                     resolve_error, \n",
    "                                                     execute_query,\n",
    "                                                     double_check_query,\n",
    "                                                     )\n",
    "from business_copilot.biz_analytics.prompts import POSTGRES_SYSTEM_MESSAGE\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langgraph.prebuilt import create_react_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cd0946-1a94-4ef6-927e-a4e4d848ba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the tools\n",
    "POSTGRES_SYSTEM_MESSAGE = \"\"\"\n",
    "You are a Data Analyst agent designed to interact with a POSTGRESQL database.\n",
    "Given an input question:\n",
    "- Create a syntactically correct query to run,\n",
    "- Look at the results of the query and return the answer. \n",
    "- Unless the user specifies a specific number of examples they wish to obtain, always limit your query to at most {top_k} results.\n",
    "\n",
    "IMPORTANT:\n",
    "- To start you should ALWAYS look at the list of tables in the database to be sure your predicted table exists. Do NOT skip this step.\n",
    "\n",
    "Check the list of tables again to be sure they are all relevant before, Get example and schema for each of the tables you predicted. \n",
    "Make sure that they exist. So, You can have context you can work with.\n",
    "\n",
    "MUST DO: You MUST double check your query before executing it. DO NOT FORGET this step.\n",
    "ONLY Then you execute the query with the most relevant table.\n",
    "\n",
    "You can order the results by a relevant column to return the most interesting\n",
    "examples in the database. Never query for all the columns from a specific table,\n",
    "only ask for the relevant columns given the question.\n",
    "\n",
    "Note:\n",
    "    If you get an error while executing the final query, that is, when using the execute_query tool \n",
    "    ONLY then can you use the resolve_error tool. to try again and resolve the error.\n",
    "VERY IMPORTANT:\n",
    "    - DO NOT make any DOMAIN DEFINITION LANGUAGE (DDL) statements such  as (CREATE, ALTER, DROP, TRUNCATE, RENAME)\n",
    "    - Also DO NOT make any DML statements (INSERT, UPDATE, DELETE etc.) to the database.\n",
    "\"\"\".format(\n",
    "    top_k=5,\n",
    ")\n",
    "\n",
    "tools = [\n",
    "    list_tables, get_relevant_schema_example,\n",
    "    resolve_error, execute_query, \n",
    "    double_check_query,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5115d3cf-2ac7-4ebe-9e1a-9a68b553c4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "# Create graph\n",
    "model = \"gpt-4o\"\n",
    "llm = init_chat_model(f\"openai:{model}\", temperature=0.0)\n",
    "agent_executor = create_react_agent(llm , tools=tools, prompt=POSTGRES_SYSTEM_MESSAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30118652-37d9-4a90-82f2-78c35e3af920",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "question =  \"Which country's customers spent the most?\"\n",
    "async for step in agent_executor.astream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": question}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573be16c-8b45-4d60-8b28-edf957a2eb27",
   "metadata": {},
   "source": [
    "### Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852f5e14-1ebe-4774-be6a-7fa966d80960",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
